{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdae782",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730bd1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 05:22:19.201478: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-16 05:22:19.201810: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "import zlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "from contextlib import contextmanager\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "_CMP = '_cmp'\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def open_db_connection(*, file, close=True,\n",
    "                       lock=None, check_same_thread=False):\n",
    "    \"\"\"\n",
    "    Safety wrapper for the database call.\n",
    "    \"\"\"\n",
    "\n",
    "    if lock is not None:\n",
    "        lock.acquire()\n",
    "\n",
    "    con = sql.connect(database=file, check_same_thread=check_same_thread)\n",
    "\n",
    "    try:\n",
    "        yield con\n",
    "\n",
    "    finally:\n",
    "        if close:\n",
    "            con.close()\n",
    "        if lock is not None:\n",
    "            lock.release()\n",
    "\n",
    "\n",
    "def get_table_name(file):\n",
    "    with open_db_connection(file=file, close=True) as con:\n",
    "        res = pd.read_sql_query(sql=\"SELECT name FROM sqlite_master WHERE type ='table' AND name NOT LIKE 'sqlite_%'\",\n",
    "                                con=con)\n",
    "        return res['name'].values\n",
    "\n",
    "\n",
    "def rename_table(file, tables):\n",
    "    old_names = get_table_name(file=file)\n",
    "\n",
    "    with open_db_connection(file=file, close=True) as con:\n",
    "        cur = con.cursor()\n",
    "        for old in old_names:\n",
    "            if old in tables:\n",
    "                new = tables['old']\n",
    "                cur.execute(f\"ALTER TABLE `{old}` RENAME TO `{new}`\")\n",
    "\n",
    "\n",
    "def get_values_sql(*, file, table='db', columns=None, rows=-1,\n",
    "                   values_only=False, squeeze_col=True, squeeze_row=True):\n",
    "    \"\"\"\n",
    "    'i_samples' == i_samples_global\n",
    "    \"\"\"\n",
    "\n",
    "    lock = None  # Lock is not necessary fo reading\n",
    "    if columns is None:\n",
    "        columns = '*'\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    columns_str = ', '.join(map(str, columns))\n",
    "\n",
    "    if isinstance(rows, int):\n",
    "        rows = [rows]\n",
    "    rows = np.array(rows)\n",
    "\n",
    "    if rows[0] == -1:  # All samples\n",
    "        with open_db_connection(file=file, close=True, lock=lock) as con:\n",
    "            df = pd.read_sql_query(con=con, sql=f\"SELECT {columns_str} FROM {table}\")  # path_db\n",
    "\n",
    "    else:\n",
    "        rows_str = rows + 1  # Attention! Unlike in Python, SQL indices start at 1\n",
    "        rows_str = ', '.join(map(str, rows_str))\n",
    "        with open_db_connection(file=file, close=True, lock=lock) as con:\n",
    "            df = pd.read_sql_query(sql=f\"SELECT {columns_str} FROM {table} WHERE ROWID in ({rows_str})\",\n",
    "                                   index_col=rows, con=con)\n",
    "\n",
    "    value_list = []\n",
    "    if np.any(columns == ['*']):\n",
    "        columns = df.columns.values\n",
    "\n",
    "    if values_only:\n",
    "        for col in columns:\n",
    "            value = __decompress_values(value=df.loc[:, col].values, col=col)\n",
    "            value_list.append(value)\n",
    "\n",
    "        if len(df) == 1 and squeeze_row:\n",
    "            for i in range(len(columns)):\n",
    "                value_list[i] = value_list[i][0]\n",
    "\n",
    "        if len(value_list) == 1 and squeeze_col:\n",
    "            value_list = value_list[0]\n",
    "\n",
    "        return value_list\n",
    "\n",
    "    # Return pandas.DataFrame\n",
    "    else:\n",
    "        for col in columns:\n",
    "            value = __decompress_values(value=df.loc[:, col].values, col=col)\n",
    "            df.loc[:, col] = numeric2object_array(value)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "def set_values_sql(*, file, table='db',\n",
    "                   values, columns, rows=-1, lock=None):\n",
    "    \"\"\"\n",
    "    Note: multidimensional numpy arrays have to be saved as flat to SQL otherwise the order is messed up\n",
    "    values = ([...], [...], [...], ...)\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle rows argument\n",
    "    if isinstance(rows, int):\n",
    "        if rows == -1:\n",
    "            rows = np.arange(len(values[0])).tolist()\n",
    "        else:\n",
    "            rows = [rows]\n",
    "\n",
    "    rows_sql = (np.array(rows) + 1).tolist()  # Attention! Unlike in Python, SQL indices start at 1\n",
    "\n",
    "    # Handle columns argument\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "\n",
    "    columns_str = '=?, '.join(map(str, columns))\n",
    "    columns_str += '=?'\n",
    "\n",
    "    values_rows_sql = change_tuple_order(values + (rows_sql,))\n",
    "    values_rows_sql = list(values_rows_sql)\n",
    "    query = f\"UPDATE {table} SET {columns_str} WHERE ROWID=?\"\n",
    "\n",
    "    with open_db_connection(file=file, close=True, lock=lock) as con:\n",
    "        cur = con.cursor()\n",
    "        if len(values_rows_sql) == 1:\n",
    "            cur.execute(query, values_rows_sql[0])\n",
    "        else:\n",
    "            cur.executemany(query, values_rows_sql)\n",
    "\n",
    "        con.commit()\n",
    "\n",
    "\n",
    "def df2sql(df, file, table='db', if_exists='fail', lock=None):\n",
    "    \"\"\"\n",
    "    From DataFrame.to_sql():\n",
    "        if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
    "                   - fail: If table exists, do nothing.\n",
    "                   - replace: If table exists, drop it, recreate it, and insert Measurements.\n",
    "                   - append: If table exists, insert Measurements. Create if does not exist.\n",
    "    \"\"\"\n",
    "    with open_db_connection(file=file, close=True, lock=lock) as con:\n",
    "        df.to_sql(name=table, con=con, if_exists=if_exists, index=False)\n",
    "\n",
    "\n",
    "# Helper\n",
    "# Image Compression <-> Decompression\n",
    "def __decompress_values(value, col):\n",
    "    # SQL saves everything in binary form -> convert back to numeric, expect the columns which are marked as CMP\n",
    "    if isinstance(value[0], bytes) and col[-4:] != _CMP:\n",
    "        if col in ['i_world', 'i_sample', 'n_obstacles']:\n",
    "            value = np.array([np.frombuffer(v, dtype=int) for v in value], dtype=int)\n",
    "        elif col in ['rectangle_pos', 'rectangle_position', 'rectangle_size']:\n",
    "            value = np.array([np.frombuffer(v, dtype=int) for v in value], dtype=object)\n",
    "        else:\n",
    "            value = np.array([np.frombuffer(v, dtype=float) for v in value])\n",
    "        value = np.squeeze(value)\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def change_tuple_order(tpl):\n",
    "    return tuple(map(lambda *tt: tuple(tt), *tpl))\n",
    "\n",
    "\n",
    "def numeric2object_array(arr):\n",
    "    n = arr.shape[0]\n",
    "    arr_obj = np.zeros(n, dtype=object)\n",
    "    for i in range(n):\n",
    "        arr_obj[i] = arr[i]\n",
    "\n",
    "    return arr_obj\n",
    "\n",
    "\n",
    "def object2numeric_array(arr):\n",
    "    s = np.shape(arr)\n",
    "    arr = np.array([v for v in np.ravel(arr)])\n",
    "    arr = np.reshape(arr, s + np.shape(arr)[1:])\n",
    "    return arr\n",
    "\n",
    "\n",
    "def initialize_array(shape, mode='zeros', dtype=None, order='c'):\n",
    "\n",
    "    if mode == 'zeros':\n",
    "        return np.zeros(shape, dtype=dtype, order=order)\n",
    "    elif mode == 'ones':\n",
    "        return np.ones(shape, dtype=dtype, order=order)\n",
    "    elif mode == 'empty':\n",
    "        return np.empty(shape, dtype=dtype, order=order)\n",
    "    elif mode == 'random':\n",
    "        return np.random.random(shape).astype(dtype=dtype, order=order)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown initialization method {mode}\")\n",
    "\n",
    "\n",
    "def __dim_voxels(n_voxels, n_dim=None):\n",
    "    if np.size(n_voxels) == 1:\n",
    "        try:\n",
    "            n_voxels = tuple(n_voxels)\n",
    "        except TypeError:\n",
    "            n_voxels = (n_voxels,)\n",
    "        n_voxels *= n_dim\n",
    "    else:\n",
    "        n_voxels = tuple(n_voxels)\n",
    "\n",
    "    return n_voxels\n",
    "\n",
    "\n",
    "def image_array_shape(n_voxels, n_samples=None, n_dim=None, n_channels=None):\n",
    "    \"\"\"\n",
    "    Helper to set the shape for an image array.\n",
    "    n_samples=100,  n_voxels=64,          n_dim=2,    n_channels=None  ->  (100, 64, 64)\n",
    "    n_samples=100,  n_voxels=64,          n_dim=3,    n_channels=2     ->  (100, 64, 64, 64, 2)\n",
    "    n_samples=None, n_voxel=(10, 11, 12), n_dim=None, n_channels=None  ->  (10, 11, 12)\n",
    "    \"\"\"\n",
    "\n",
    "    shape = __dim_voxels(n_voxels=n_voxels, n_dim=n_dim)\n",
    "\n",
    "    if n_samples is not None:\n",
    "        shape = (n_samples,) + shape\n",
    "    if n_channels is not None:\n",
    "        shape = shape + (n_channels,)\n",
    "\n",
    "    return shape\n",
    "\n",
    "\n",
    "def initialize_image_array(n_voxels, n_dim=None, n_samples=None, n_channels=None,\n",
    "                           dtype=bool, initialization='zeros'):\n",
    "    shape = image_array_shape(n_voxels=n_voxels, n_dim=n_dim, n_samples=n_samples, n_channels=n_channels)\n",
    "    return initialize_array(shape=shape, mode=initialization, dtype=dtype)\n",
    "\n",
    "\n",
    "# Image Compression <-> Decompression\n",
    "def img2compressed(img, n_dim=-1, level=9):\n",
    "    \"\"\"\n",
    "    Compress the given image with the zlib routine to a binary string.\n",
    "    Level of compression can be adjusted. A timing with respect to different compression levels for decompression showed\n",
    "    no difference, so the highest level is default, this corresponds to the largest compression.\n",
    "    For compression it is slightly slower but this happens just once and not during keras training, so the smaller\n",
    "    needed memory was favoured.\n",
    "    Alternative:\n",
    "    <-> use numpy sparse for the world images, especially in 3d  -> zlib is more effective and more general\n",
    "    \"\"\"\n",
    "\n",
    "    if n_dim == -1:\n",
    "        return zlib.compress(img.tobytes(), level=level)\n",
    "    else:\n",
    "        shape = img.shape[:-n_dim]\n",
    "        img_cmp = np.empty(shape, dtype=object)\n",
    "        for idx in np.ndindex(*shape):\n",
    "            img_cmp[idx] = zlib.compress(img[idx, ...].tobytes(), level=level)\n",
    "        return img_cmp\n",
    "\n",
    "\n",
    "def compressed2img(img_cmp, n_voxels, n_dim=None, n_channels=None, dtype=bool):\n",
    "    \"\"\"\n",
    "    Decompress the binary string back to an image of given shape\n",
    "    \"\"\"\n",
    "\n",
    "    shape = np.shape(img_cmp)\n",
    "\n",
    "    if shape:\n",
    "        n_samples = np.size(img_cmp)\n",
    "        img_arr = initialize_image_array(n_voxels=n_voxels, n_dim=n_dim, n_samples=n_samples, n_channels=n_channels,\n",
    "                                         dtype=dtype)\n",
    "        for i in range(n_samples):\n",
    "            img_arr[i, ...] = np.fromstring(zlib.decompress(img_cmp[i]), dtype=dtype).reshape(\n",
    "                image_array_shape(n_voxels=n_voxels, n_dim=n_dim, n_channels=n_channels))\n",
    "        return img_arr\n",
    "\n",
    "    else:\n",
    "        return np.fromstring(zlib.decompress(img_cmp), dtype=dtype).reshape(\n",
    "            image_array_shape(n_voxels=n_voxels, n_dim=n_dim, n_channels=n_channels))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class create_dataset(tf.keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            x[j] = img\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            y[j] = np.expand_dims(img, 2)\n",
    "            # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
    "            y[j] -= 1\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a23508",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfb5ed6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1363/3336820032.py:279: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_arr[i, ...] = np.fromstring(zlib.decompress(img_cmp[i]), dtype=dtype).reshape(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file = '../SingleSphere02.db'\n",
    "# TODO change to you own directory\n",
    "\n",
    "\n",
    "n_voxels = 64\n",
    "voxel_size = 10 / 64     # in m\n",
    "extent = [0, 10, 0, 10]  # in m\n",
    "n_waypoints = 22  # start + 20 inner points + end\n",
    "n_dim = 2\n",
    "n_paths_per_world = 1000\n",
    "n_worlds = 5000\n",
    "\n",
    "\n",
    "worlds = get_values_sql(file=file, table='worlds')\n",
    "obstacle_images = compressed2img(img_cmp=worlds.obst_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "\n",
    "# always 1000 paths belong to one world\n",
    "# 0...999     -> world 0\n",
    "# 1000...1999 -> world 1\n",
    "# 2000...2999 -> world 2\n",
    "paths = get_values_sql(file=file, table='paths', rows=[0, 1, 2, 1000, 2000])\n",
    "path_images = compressed2img(img_cmp=paths.path_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "start_images = compressed2img(img_cmp=paths.start_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "end_images = compressed2img(img_cmp=paths.end_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "\n",
    "q_paths = object2numeric_array(paths.q_path.values)\n",
    "q_paths = q_paths.reshape(-1, n_waypoints, n_dim)\n",
    "\n",
    "# Plot an example\n",
    "i = 0\n",
    "i_world = paths.i_world[i]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(obstacle_images[i_world].T, origin='lower', extent=extent, cmap='binary',)\n",
    "ax.imshow(start_images[i].T, origin='lower', extent=extent, cmap='Greens', alpha=0.4)\n",
    "ax.imshow(end_images[i].T, origin='lower', extent=extent, cmap='Reds', alpha=0.4)\n",
    "ax.imshow(path_images[i].T, origin='lower', extent=extent, cmap='Blues', alpha=0.2)\n",
    "ax.axis('off')\n",
    "ax.plot(*q_paths[i].T, color='k', marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea6a80",
   "metadata": {},
   "source": [
    "# Creating Input/Output Image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe61c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_for_single_world(world_index, file='../SingleSphere02.db', paths_per_world=1000):\n",
    "    \n",
    "    \"\"\" Returns an array of tuples where each tuple contains:\n",
    "        1. Obstacle image of the desired world with different start & end points\n",
    "        2. Above image plus the path from start to end point\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initial Parameters\n",
    "    n_voxels = 64\n",
    "    voxel_size = 10 / 64     # in m\n",
    "    extent = [0, 10, 0, 10]  # in m\n",
    "    n_waypoints = 22  # start + 20 inner points + end\n",
    "    n_dim = 2\n",
    "    n_paths_per_world = 1000\n",
    "    n_worlds = 5000\n",
    "\n",
    "    worlds = get_values_sql(file=file, table='worlds')\n",
    "    obstacle_image = compressed2img(img_cmp=worlds.obst_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)[world_index]\n",
    "    \n",
    "    # always 1000 paths belong to one world\n",
    "    # 0...999     -> world 0\n",
    "    # 1000...1999 -> world 1\n",
    "    # 2000...2999 -> world 2\n",
    "    path_range_start  = world_index * paths_per_world\n",
    "    path_range_end = world_index * paths_per_world + paths_per_world\n",
    "    n_world_all_paths = [x for x in range(path_range_start, path_range_end)]\n",
    "    \n",
    "    paths = get_values_sql(file=file, table='paths', rows=n_world_all_paths)\n",
    "    \n",
    "    # Decompressing objects to images\n",
    "    path_images = compressed2img(img_cmp=paths.path_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "    start_images = compressed2img(img_cmp=paths.start_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "    end_images = compressed2img(img_cmp=paths.end_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "\n",
    "    input_images = []\n",
    "    output_images = []\n",
    "    for i in range(len(n_world_all_paths)):\n",
    "        input_images.append(np.concatenate((obstacle_image.T[:,:,np.newaxis], start_images[i].T[:,:,np.newaxis],end_images[i].T[:,:,np.newaxis]), axis=-1))\n",
    "        #input_images.append(obstacle_images[i_world].T + start_images[i].T + end_images[i].T)\n",
    "        output_images.append(np.expand_dims(path_images[i].T, axis=-1))\n",
    "    return input_images, output_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f24b8bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1363/3336820032.py:279: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_arr[i, ...] = np.fromstring(zlib.decompress(img_cmp[i]), dtype=dtype).reshape(\n"
     ]
    }
   ],
   "source": [
    "input_images, output_images = load_images_for_single_world(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9108408f",
   "metadata": {},
   "source": [
    "# Image Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a994b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_np_arrays(list_of_images):\n",
    "    ''' Returns a singular numpy array from a list of images. \\\n",
    "        It is used to arrange images to be compatible while making tensorflow datasets\n",
    "    '''\n",
    "    \n",
    "    length = list_of_images[0].shape[0]\n",
    "    width  = list_of_images[0].shape[1]\n",
    "    depth  = list_of_images[0].shape[2]\n",
    "    \n",
    "    imgs   = np.empty((0, length, width, depth))\n",
    "    \n",
    "    for img in list_of_images:\n",
    "        imgs = np.append(imgs, np.array(img).reshape((1, length, width, depth)), axis=0)\n",
    "        \n",
    "    return imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50542db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Images Shape after Reshaping:  (1000, 64, 64, 3)\n",
      "Output Images Shape after Reshaping:  (1000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "input_images = np.reshape(input_images, (-1, 64, 64, 3))\n",
    "print(\"Input Images Shape after Reshaping: \",input_images.shape)\n",
    "\n",
    "output_images = np.reshape(output_images, (-1, 64, 64, 1))\n",
    "print(\"Output Images Shape after Reshaping: \",output_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8b4bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list_to_np_arrays(input_images)\n",
    "y = list_to_np_arrays(output_images)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "labels_train = labels_train.astype(np.bool_)\n",
    "labels_test = labels_test.astype(np.bool_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f6530",
   "metadata": {},
   "source": [
    "# Sample Input and Output Data Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "22341f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sample Output')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx=10\n",
    "path = labels_test[idx]\n",
    "path = path == 0\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(13,13))\n",
    "\n",
    "\n",
    "axs[0].imshow((data_test[idx]*255).astype(np.uint8),)\n",
    "axs[0].set_title('Sample Input')\n",
    "#axs[0].imshow((path*255).astype(np.uint8), cmap='Blues', alpha=0.2)\n",
    "\n",
    "axs[1].imshow((data_test[idx]*255).astype(np.uint8),)\n",
    "axs[1].imshow((path*255).astype(np.uint8), cmap='Blues', alpha=0.4)\n",
    "axs[1].set_title('Sample Output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b48f8e",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbd23028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_size, num_classes):   \n",
    "    inputs = tf.keras.layers.Input(shape=img_size + (3,))\n",
    "    #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    #Expansive path \n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f0c16f",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66a5f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (64,64)\n",
    "model = get_model(img_size, 3)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d0ce640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/40 [==============================] - 61s 1s/step - loss: 0.3892 - accuracy: 0.8906\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 53s 1s/step - loss: 0.1759 - accuracy: 0.9442\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 52s 1s/step - loss: 0.1367 - accuracy: 0.9506\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 58s 1s/step - loss: 0.1153 - accuracy: 0.9514\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 53s 1s/step - loss: 0.0979 - accuracy: 0.9521\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 52s 1s/step - loss: 0.0808 - accuracy: 0.9614\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 52s 1s/step - loss: 0.0651 - accuracy: 0.9716\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 51s 1s/step - loss: 0.0605 - accuracy: 0.9749\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 55s 1s/step - loss: 0.0519 - accuracy: 0.9786\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 74s 2s/step - loss: 0.0481 - accuracy: 0.9805\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 61s 2s/step - loss: 0.0445 - accuracy: 0.9820\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 62s 2s/step - loss: 0.0437 - accuracy: 0.9824\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 62s 2s/step - loss: 0.0376 - accuracy: 0.9850\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 62s 2s/step - loss: 0.0344 - accuracy: 0.9859\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 71s 2s/step - loss: 0.0334 - accuracy: 0.9866\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 67s 2s/step - loss: 0.0341 - accuracy: 0.9868\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 63s 2s/step - loss: 0.0305 - accuracy: 0.9877\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 66s 2s/step - loss: 0.0294 - accuracy: 0.9881\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 62s 2s/step - loss: 0.0281 - accuracy: 0.9886\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 65s 2s/step - loss: 0.0270 - accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "STEPS_PER_EPOCH=40\n",
    "model_history = model.fit(data_train, labels_train, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7879d84",
   "metadata": {},
   "source": [
    "# Predictions vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "696ccb7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c6cbd9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predicted Image')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 10\n",
    "y_pred_processed = (y_pred < 0.6).astype(np.uint8)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(13,13))\n",
    "\n",
    "\n",
    "# Plotting the Ground Truth Image\n",
    "path = labels_test[idx]\n",
    "path = path == 0\n",
    "\n",
    "axs[0].imshow((data_test[idx]*255).astype(np.uint8),)\n",
    "axs[0].imshow((path*255).astype(np.uint8), cmap='Blues', alpha=0.4)\n",
    "axs[0].set_title(\"Ground Truth Image\")\n",
    "\n",
    "\n",
    "# Plotting the Predicted Image\n",
    "axs[1].imshow((data_test[idx]*255).astype(np.uint8),)\n",
    "axs[1].imshow((y_pred_processed[idx]*255).astype(np.uint8),  cmap='Blues', alpha=0.4)\n",
    "axs[1].set_title(\"Predicted Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9de17a",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
