{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdae782",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730bd1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 05:21:30.322331: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-16 05:21:30.322485: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import zlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "from contextlib import contextmanager\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "\n",
    "_CMP = '_cmp'\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def open_db_connection(*, file, close=True,\n",
    "                       lock=None, check_same_thread=False):\n",
    "    \"\"\"\n",
    "    Safety wrapper for the database call.\n",
    "    \"\"\"\n",
    "\n",
    "    if lock is not None:\n",
    "        lock.acquire()\n",
    "\n",
    "    con = sql.connect(database=file, check_same_thread=check_same_thread)\n",
    "\n",
    "    try:\n",
    "        yield con\n",
    "\n",
    "    finally:\n",
    "        if close:\n",
    "            con.close()\n",
    "        if lock is not None:\n",
    "            lock.release()\n",
    "\n",
    "\n",
    "def get_table_name(file):\n",
    "    with open_db_connection(file=file, close=True) as con:\n",
    "        res = pd.read_sql_query(sql=\"SELECT name FROM sqlite_master WHERE type ='table' AND name NOT LIKE 'sqlite_%'\",\n",
    "                                con=con)\n",
    "        return res['name'].values\n",
    "\n",
    "\n",
    "def rename_table(file, tables):\n",
    "    old_names = get_table_name(file=file)\n",
    "\n",
    "    with open_db_connection(file=file, close=True) as con:\n",
    "        cur = con.cursor()\n",
    "        for old in old_names:\n",
    "            if old in tables:\n",
    "                new = tables['old']\n",
    "                cur.execute(f\"ALTER TABLE `{old}` RENAME TO `{new}`\")\n",
    "\n",
    "\n",
    "def get_values_sql(*, file, table='db', columns=None, rows=-1,\n",
    "                   values_only=False, squeeze_col=True, squeeze_row=True):\n",
    "    \"\"\"\n",
    "    'i_samples' == i_samples_global\n",
    "    \"\"\"\n",
    "\n",
    "    lock = None  # Lock is not necessary fo reading\n",
    "    if columns is None:\n",
    "        columns = '*'\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    columns_str = ', '.join(map(str, columns))\n",
    "\n",
    "    if isinstance(rows, int):\n",
    "        rows = [rows]\n",
    "    rows = np.array(rows)\n",
    "\n",
    "    if rows[0] == -1:  # All samples\n",
    "        with open_db_connection(file=file, close=True, lock=lock) as con:\n",
    "            df = pd.read_sql_query(con=con, sql=f\"SELECT {columns_str} FROM {table}\")  # path_db\n",
    "\n",
    "    else:\n",
    "        rows_str = rows + 1  # Attention! Unlike in Python, SQL indices start at 1\n",
    "        rows_str = ', '.join(map(str, rows_str))\n",
    "        with open_db_connection(file=file, close=True, lock=lock) as con:\n",
    "            df = pd.read_sql_query(sql=f\"SELECT {columns_str} FROM {table} WHERE ROWID in ({rows_str})\",\n",
    "                                   index_col=rows, con=con)\n",
    "\n",
    "    value_list = []\n",
    "    if np.any(columns == ['*']):\n",
    "        columns = df.columns.values\n",
    "\n",
    "    if values_only:\n",
    "        for col in columns:\n",
    "            value = __decompress_values(value=df.loc[:, col].values, col=col)\n",
    "            value_list.append(value)\n",
    "\n",
    "        if len(df) == 1 and squeeze_row:\n",
    "            for i in range(len(columns)):\n",
    "                value_list[i] = value_list[i][0]\n",
    "\n",
    "        if len(value_list) == 1 and squeeze_col:\n",
    "            value_list = value_list[0]\n",
    "\n",
    "        return value_list\n",
    "\n",
    "    # Return pandas.DataFrame\n",
    "    else:\n",
    "        for col in columns:\n",
    "            value = __decompress_values(value=df.loc[:, col].values, col=col)\n",
    "            df.loc[:, col] = numeric2object_array(value)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "def set_values_sql(*, file, table='db',\n",
    "                   values, columns, rows=-1, lock=None):\n",
    "    \"\"\"\n",
    "    Note: multidimensional numpy arrays have to be saved as flat to SQL otherwise the order is messed up\n",
    "    values = ([...], [...], [...], ...)\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle rows argument\n",
    "    if isinstance(rows, int):\n",
    "        if rows == -1:\n",
    "            rows = np.arange(len(values[0])).tolist()\n",
    "        else:\n",
    "            rows = [rows]\n",
    "\n",
    "    rows_sql = (np.array(rows) + 1).tolist()  # Attention! Unlike in Python, SQL indices start at 1\n",
    "\n",
    "    # Handle columns argument\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "\n",
    "    columns_str = '=?, '.join(map(str, columns))\n",
    "    columns_str += '=?'\n",
    "\n",
    "    values_rows_sql = change_tuple_order(values + (rows_sql,))\n",
    "    values_rows_sql = list(values_rows_sql)\n",
    "    query = f\"UPDATE {table} SET {columns_str} WHERE ROWID=?\"\n",
    "\n",
    "    with open_db_connection(file=file, close=True, lock=lock) as con:\n",
    "        cur = con.cursor()\n",
    "        if len(values_rows_sql) == 1:\n",
    "            cur.execute(query, values_rows_sql[0])\n",
    "        else:\n",
    "            cur.executemany(query, values_rows_sql)\n",
    "\n",
    "        con.commit()\n",
    "\n",
    "\n",
    "def df2sql(df, file, table='db', if_exists='fail', lock=None):\n",
    "    \"\"\"\n",
    "    From DataFrame.to_sql():\n",
    "        if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
    "                   - fail: If table exists, do nothing.\n",
    "                   - replace: If table exists, drop it, recreate it, and insert Measurements.\n",
    "                   - append: If table exists, insert Measurements. Create if does not exist.\n",
    "    \"\"\"\n",
    "    with open_db_connection(file=file, close=True, lock=lock) as con:\n",
    "        df.to_sql(name=table, con=con, if_exists=if_exists, index=False)\n",
    "\n",
    "\n",
    "# Helper\n",
    "# Image Compression <-> Decompression\n",
    "def __decompress_values(value, col):\n",
    "    # SQL saves everything in binary form -> convert back to numeric, expect the columns which are marked as CMP\n",
    "    if isinstance(value[0], bytes) and col[-4:] != _CMP:\n",
    "        if col in ['i_world', 'i_sample', 'n_obstacles']:\n",
    "            value = np.array([np.frombuffer(v, dtype=int) for v in value], dtype=int)\n",
    "        elif col in ['rectangle_pos', 'rectangle_position', 'rectangle_size']:\n",
    "            value = np.array([np.frombuffer(v, dtype=int) for v in value], dtype=object)\n",
    "        else:\n",
    "            value = np.array([np.frombuffer(v, dtype=float) for v in value])\n",
    "        value = np.squeeze(value)\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def change_tuple_order(tpl):\n",
    "    return tuple(map(lambda *tt: tuple(tt), *tpl))\n",
    "\n",
    "\n",
    "def numeric2object_array(arr):\n",
    "    n = arr.shape[0]\n",
    "    arr_obj = np.zeros(n, dtype=object)\n",
    "    for i in range(n):\n",
    "        arr_obj[i] = arr[i]\n",
    "\n",
    "    return arr_obj\n",
    "\n",
    "\n",
    "def object2numeric_array(arr):\n",
    "    s = np.shape(arr)\n",
    "    arr = np.array([v for v in np.ravel(arr)])\n",
    "    arr = np.reshape(arr, s + np.shape(arr)[1:])\n",
    "    return arr\n",
    "\n",
    "\n",
    "def initialize_array(shape, mode='zeros', dtype=None, order='c'):\n",
    "\n",
    "    if mode == 'zeros':\n",
    "        return np.zeros(shape, dtype=dtype, order=order)\n",
    "    elif mode == 'ones':\n",
    "        return np.ones(shape, dtype=dtype, order=order)\n",
    "    elif mode == 'empty':\n",
    "        return np.empty(shape, dtype=dtype, order=order)\n",
    "    elif mode == 'random':\n",
    "        return np.random.random(shape).astype(dtype=dtype, order=order)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown initialization method {mode}\")\n",
    "\n",
    "\n",
    "def __dim_voxels(n_voxels, n_dim=None):\n",
    "    if np.size(n_voxels) == 1:\n",
    "        try:\n",
    "            n_voxels = tuple(n_voxels)\n",
    "        except TypeError:\n",
    "            n_voxels = (n_voxels,)\n",
    "        n_voxels *= n_dim\n",
    "    else:\n",
    "        n_voxels = tuple(n_voxels)\n",
    "\n",
    "    return n_voxels\n",
    "\n",
    "\n",
    "def image_array_shape(n_voxels, n_samples=None, n_dim=None, n_channels=None):\n",
    "    \"\"\"\n",
    "    Helper to set the shape for an image array.\n",
    "    n_samples=100,  n_voxels=64,          n_dim=2,    n_channels=None  ->  (100, 64, 64)\n",
    "    n_samples=100,  n_voxels=64,          n_dim=3,    n_channels=2     ->  (100, 64, 64, 64, 2)\n",
    "    n_samples=None, n_voxel=(10, 11, 12), n_dim=None, n_channels=None  ->  (10, 11, 12)\n",
    "    \"\"\"\n",
    "\n",
    "    shape = __dim_voxels(n_voxels=n_voxels, n_dim=n_dim)\n",
    "\n",
    "    if n_samples is not None:\n",
    "        shape = (n_samples,) + shape\n",
    "    if n_channels is not None:\n",
    "        shape = shape + (n_channels,)\n",
    "\n",
    "    return shape\n",
    "\n",
    "\n",
    "def initialize_image_array(n_voxels, n_dim=None, n_samples=None, n_channels=None,\n",
    "                           dtype=bool, initialization='zeros'):\n",
    "    shape = image_array_shape(n_voxels=n_voxels, n_dim=n_dim, n_samples=n_samples, n_channels=n_channels)\n",
    "    return initialize_array(shape=shape, mode=initialization, dtype=dtype)\n",
    "\n",
    "\n",
    "# Image Compression <-> Decompression\n",
    "def img2compressed(img, n_dim=-1, level=9):\n",
    "    \"\"\"\n",
    "    Compress the given image with the zlib routine to a binary string.\n",
    "    Level of compression can be adjusted. A timing with respect to different compression levels for decompression showed\n",
    "    no difference, so the highest level is default, this corresponds to the largest compression.\n",
    "    For compression it is slightly slower but this happens just once and not during keras training, so the smaller\n",
    "    needed memory was favoured.\n",
    "    Alternative:\n",
    "    <-> use numpy sparse for the world images, especially in 3d  -> zlib is more effective and more general\n",
    "    \"\"\"\n",
    "\n",
    "    if n_dim == -1:\n",
    "        return zlib.compress(img.tobytes(), level=level)\n",
    "    else:\n",
    "        shape = img.shape[:-n_dim]\n",
    "        img_cmp = np.empty(shape, dtype=object)\n",
    "        for idx in np.ndindex(*shape):\n",
    "            img_cmp[idx] = zlib.compress(img[idx, ...].tobytes(), level=level)\n",
    "        return img_cmp\n",
    "\n",
    "\n",
    "def compressed2img(img_cmp, n_voxels, n_dim=None, n_channels=None, dtype=bool):\n",
    "    \"\"\"\n",
    "    Decompress the binary string back to an image of given shape\n",
    "    \"\"\"\n",
    "\n",
    "    shape = np.shape(img_cmp)\n",
    "\n",
    "    if shape:\n",
    "        n_samples = np.size(img_cmp)\n",
    "        img_arr = initialize_image_array(n_voxels=n_voxels, n_dim=n_dim, n_samples=n_samples, n_channels=n_channels,\n",
    "                                         dtype=dtype)\n",
    "        for i in range(n_samples):\n",
    "            img_arr[i, ...] = np.fromstring(zlib.decompress(img_cmp[i]), dtype=dtype).reshape(\n",
    "                image_array_shape(n_voxels=n_voxels, n_dim=n_dim, n_channels=n_channels))\n",
    "        return img_arr\n",
    "\n",
    "    else:\n",
    "        return np.fromstring(zlib.decompress(img_cmp), dtype=dtype).reshape(\n",
    "            image_array_shape(n_voxels=n_voxels, n_dim=n_dim, n_channels=n_channels))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class create_dataset(tf.keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            x[j] = img\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            y[j] = np.expand_dims(img, 2)\n",
    "            # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
    "            y[j] -= 1\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a23508",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfb5ed6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1378/1134103436.py:278: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_arr[i, ...] = np.fromstring(zlib.decompress(img_cmp[i]), dtype=dtype).reshape(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file = '../SingleSphere02.db'\n",
    "# TODO change to you own directory\n",
    "\n",
    "\n",
    "n_voxels = 64\n",
    "voxel_size = 10 / 64     # in m\n",
    "extent = [0, 10, 0, 10]  # in m\n",
    "n_waypoints = 22  # start + 20 inner points + end\n",
    "n_dim = 2\n",
    "n_paths_per_world = 1000\n",
    "n_worlds = 5000\n",
    "\n",
    "\n",
    "worlds = get_values_sql(file=file, table='worlds')\n",
    "obstacle_images = compressed2img(img_cmp=worlds.obst_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "\n",
    "# always 1000 paths belong to one world\n",
    "# 0...999     -> world 0\n",
    "# 1000...1999 -> world 1\n",
    "# 2000...2999 -> world 2\n",
    "paths = get_values_sql(file=file, table='paths', rows=[0, 1, 2, 1000, 2000])\n",
    "path_images = compressed2img(img_cmp=paths.path_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "start_images = compressed2img(img_cmp=paths.start_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "end_images = compressed2img(img_cmp=paths.end_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "\n",
    "q_paths = object2numeric_array(paths.q_path.values)\n",
    "q_paths = q_paths.reshape(-1, n_waypoints, n_dim)\n",
    "\n",
    "# Plot an example\n",
    "i = 0\n",
    "i_world = paths.i_world[i]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(obstacle_images[i_world].T, origin='lower', extent=extent, cmap='binary',)\n",
    "ax.imshow(start_images[i].T, origin='lower', extent=extent, cmap='Greens', alpha=0.4)\n",
    "ax.imshow(end_images[i].T, origin='lower', extent=extent, cmap='Reds', alpha=0.4)\n",
    "ax.imshow(path_images[i].T, origin='lower', extent=extent, cmap='Blues', alpha=0.2)\n",
    "ax.axis('off')\n",
    "ax.plot(*q_paths[i].T, color='k', marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea6a80",
   "metadata": {},
   "source": [
    "# Creating Input/Output Image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe61c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_for_single_world(world_index, file='../SingleSphere02.db', paths_per_world=1000):\n",
    "    \n",
    "    \"\"\" Returns an array of tuples where each tuple contains:\n",
    "        1. Obstacle image of the desired world with different start & end points\n",
    "        2. Above image plus the path from start to end point\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initial Parameters\n",
    "    n_voxels = 64\n",
    "    voxel_size = 10 / 64     # in m\n",
    "    extent = [0, 10, 0, 10]  # in m\n",
    "    n_waypoints = 22  # start + 20 inner points + end\n",
    "    n_dim = 2\n",
    "    n_paths_per_world = 1000\n",
    "    n_worlds = 5000\n",
    "\n",
    "    worlds = get_values_sql(file=file, table='worlds')\n",
    "    obstacle_image = compressed2img(img_cmp=worlds.obst_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)[world_index]\n",
    "    \n",
    "    # always 1000 paths belong to one world\n",
    "    # 0...999     -> world 0\n",
    "    # 1000...1999 -> world 1\n",
    "    # 2000...2999 -> world 2\n",
    "    path_range_start  = world_index * paths_per_world\n",
    "    path_range_end = world_index * paths_per_world + paths_per_world\n",
    "    n_world_all_paths = [x for x in range(path_range_start, path_range_end)]\n",
    "    \n",
    "    paths = get_values_sql(file=file, table='paths', rows=n_world_all_paths)\n",
    "    \n",
    "    # Decompressing objects to images\n",
    "    path_images = compressed2img(img_cmp=paths.path_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "    start_images = compressed2img(img_cmp=paths.start_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "    end_images = compressed2img(img_cmp=paths.end_img_cmp.values, n_voxels=n_voxels, n_dim=n_dim)\n",
    "\n",
    "    input_images = []\n",
    "    output_images = []\n",
    "    for i in range(len(n_world_all_paths)):\n",
    "        input_images.append(np.concatenate((obstacle_image.T[:,:,np.newaxis], start_images[i].T[:,:,np.newaxis],end_images[i].T[:,:,np.newaxis]), axis=-1))\n",
    "        #input_images.append(obstacle_images[i_world].T + start_images[i].T + end_images[i].T)\n",
    "        output_images.append(path_images[i].T)\n",
    "    return input_images, output_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f24b8bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1378/1134103436.py:278: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_arr[i, ...] = np.fromstring(zlib.decompress(img_cmp[i]), dtype=dtype).reshape(\n"
     ]
    }
   ],
   "source": [
    "input_images, output_images = load_images_for_single_world(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5be9afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverting colors of images\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "for i in range(len(input_images)):\n",
    "    im = Image.fromarray((input_images[i]*255).astype(np.uint8))\n",
    "    input_images[i] = np.array(PIL.ImageOps.invert(im))\n",
    "    \n",
    "for j in range(len(output_images)):    \n",
    "    im = Image.fromarray((output_images[j]*255).astype(np.uint8))\n",
    "    output_images[j] = np.array(PIL.ImageOps.invert(im))\n",
    "    output_images[j] = np.expand_dims(output_images[j], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9108408f",
   "metadata": {},
   "source": [
    "# Images Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a994b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_np_arrays(list_of_images):\n",
    "    ''' Returns a singular numpy array from a list of images. \\\n",
    "        It is used to arrange images to be compatible while making tensorflow datasets\n",
    "    '''\n",
    "    \n",
    "    length = list_of_images[0].shape[0]\n",
    "    width  = list_of_images[0].shape[1]\n",
    "    depth  = list_of_images[0].shape[2]\n",
    "    \n",
    "    imgs   = np.empty((0, length, width, depth))\n",
    "    \n",
    "    for img in list_of_images:\n",
    "        imgs = np.append(imgs, np.array(img).reshape((1, length, width, depth)), axis=0)\n",
    "        \n",
    "    return imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50542db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Images Shape after Reshaping:  (1000, 64, 64, 3)\n",
      "Output Images Shape after Reshaping:  (1000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "input_images = np.reshape(input_images, (-1, 64, 64, 3))\n",
    "print(\"Input Images Shape after Reshaping: \",input_images.shape)\n",
    "\n",
    "output_images = np.reshape(output_images, (-1, 64, 64, 1))\n",
    "print(\"Output Images Shape after Reshaping: \",output_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b4bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list_to_np_arrays(input_images)\n",
    "y = list_to_np_arrays(output_images)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "labels_train = labels_train.astype(np.bool_)\n",
    "labels_test = labels_test.astype(np.bool_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55128176",
   "metadata": {},
   "source": [
    "# Sample Input and Output Data Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92d2ec57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sample Output')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx=10\n",
    "path = labels_test[idx]\n",
    "path = path == 0\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(13,13))\n",
    "\n",
    "axs[0].imshow((data_test[idx]).astype(np.uint8))\n",
    "axs[0].set_title('Sample Input')\n",
    "\n",
    "axs[1].imshow((data_test[idx]).astype(np.uint8))\n",
    "axs[1].imshow((path*255).astype(np.uint8), cmap='Reds', alpha=0.2)\n",
    "axs[1].set_title('Sample Output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b48f8e",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd23028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_size, num_classes):   \n",
    "    inputs = tf.keras.layers.Input(shape=img_size + (3,))\n",
    "    #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    #Expansive path \n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d6bb8",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66a5f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (64,64)\n",
    "model = get_model(img_size, 3)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d0ce640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "40/40 [==============================] - 36s 857ms/step - loss: 39.5039 - accuracy: 0.8071\n",
      "Epoch 2/40\n",
      "40/40 [==============================] - 32s 794ms/step - loss: 1.6713 - accuracy: 0.8818\n",
      "Epoch 3/40\n",
      "40/40 [==============================] - 33s 838ms/step - loss: 0.6882 - accuracy: 0.8942\n",
      "Epoch 4/40\n",
      "40/40 [==============================] - 27s 666ms/step - loss: 0.3858 - accuracy: 0.9090\n",
      "Epoch 5/40\n",
      "40/40 [==============================] - 34s 866ms/step - loss: 0.2993 - accuracy: 0.9226\n",
      "Epoch 6/40\n",
      "40/40 [==============================] - 37s 896ms/step - loss: 0.2593 - accuracy: 0.9302\n",
      "Epoch 7/40\n",
      "40/40 [==============================] - 27s 689ms/step - loss: 0.2394 - accuracy: 0.9344\n",
      "Epoch 8/40\n",
      "40/40 [==============================] - 35s 875ms/step - loss: 0.2254 - accuracy: 0.9366\n",
      "Epoch 9/40\n",
      "40/40 [==============================] - 54s 1s/step - loss: 0.2127 - accuracy: 0.9375\n",
      "Epoch 10/40\n",
      "40/40 [==============================] - 51s 1s/step - loss: 0.1902 - accuracy: 0.9381\n",
      "Epoch 11/40\n",
      "40/40 [==============================] - 50s 1s/step - loss: 0.1763 - accuracy: 0.9378\n",
      "Epoch 12/40\n",
      "40/40 [==============================] - 60s 2s/step - loss: 0.1537 - accuracy: 0.9387\n",
      "Epoch 13/40\n",
      "40/40 [==============================] - 53s 1s/step - loss: 0.1283 - accuracy: 0.9406\n",
      "Epoch 14/40\n",
      "40/40 [==============================] - 49s 1s/step - loss: 0.1110 - accuracy: 0.9434\n",
      "Epoch 15/40\n",
      "40/40 [==============================] - 51s 1s/step - loss: 0.0995 - accuracy: 0.9456\n",
      "Epoch 16/40\n",
      "40/40 [==============================] - 52s 1s/step - loss: 0.0937 - accuracy: 0.9470\n",
      "Epoch 17/40\n",
      "40/40 [==============================] - 53s 1s/step - loss: 0.0900 - accuracy: 0.9477\n",
      "Epoch 18/40\n",
      "40/40 [==============================] - 74s 2s/step - loss: 0.0851 - accuracy: 0.9485\n",
      "Epoch 19/40\n",
      "40/40 [==============================] - 60s 2s/step - loss: 0.0833 - accuracy: 0.9485\n",
      "Epoch 20/40\n",
      "40/40 [==============================] - 60s 1s/step - loss: 0.0763 - accuracy: 0.9508\n",
      "Epoch 21/40\n",
      "40/40 [==============================] - 61s 2s/step - loss: 0.0758 - accuracy: 0.9666\n",
      "Epoch 22/40\n",
      "40/40 [==============================] - 61s 2s/step - loss: 0.0726 - accuracy: 0.9684\n",
      "Epoch 23/40\n",
      "40/40 [==============================] - 71s 2s/step - loss: 0.0703 - accuracy: 0.9704\n",
      "Epoch 24/40\n",
      "40/40 [==============================] - 67s 2s/step - loss: 0.0688 - accuracy: 0.9715\n",
      "Epoch 25/40\n",
      "40/40 [==============================] - 61s 2s/step - loss: 0.0662 - accuracy: 0.9731\n",
      "Epoch 26/40\n",
      "40/40 [==============================] - 61s 2s/step - loss: 0.0657 - accuracy: 0.9741\n",
      "Epoch 27/40\n",
      "40/40 [==============================] - 64s 2s/step - loss: 0.0665 - accuracy: 0.9732\n",
      "Epoch 28/40\n",
      "40/40 [==============================] - 65s 2s/step - loss: 0.0633 - accuracy: 0.9752\n",
      "Epoch 29/40\n",
      "40/40 [==============================] - 37s 922ms/step - loss: 0.0624 - accuracy: 0.9760\n",
      "Epoch 30/40\n",
      "40/40 [==============================] - 32s 808ms/step - loss: 0.0609 - accuracy: 0.9774\n",
      "Epoch 31/40\n",
      "40/40 [==============================] - 35s 874ms/step - loss: 0.0591 - accuracy: 0.9781\n",
      "Epoch 32/40\n",
      "40/40 [==============================] - 32s 812ms/step - loss: 0.0587 - accuracy: 0.9779\n",
      "Epoch 33/40\n",
      "40/40 [==============================] - 35s 868ms/step - loss: 0.0574 - accuracy: 0.9791\n",
      "Epoch 34/40\n",
      "40/40 [==============================] - 36s 906ms/step - loss: 0.0571 - accuracy: 0.9793\n",
      "Epoch 35/40\n",
      "40/40 [==============================] - 33s 802ms/step - loss: 0.0563 - accuracy: 0.9794\n",
      "Epoch 36/40\n",
      "40/40 [==============================] - 34s 846ms/step - loss: 0.0555 - accuracy: 0.9799\n",
      "Epoch 37/40\n",
      "40/40 [==============================] - 30s 750ms/step - loss: 0.0531 - accuracy: 0.9808\n",
      "Epoch 38/40\n",
      "40/40 [==============================] - 30s 751ms/step - loss: 0.0510 - accuracy: 0.9824\n",
      "Epoch 39/40\n",
      "40/40 [==============================] - 25s 625ms/step - loss: 0.0493 - accuracy: 0.9830\n",
      "Epoch 40/40\n",
      "40/40 [==============================] - 25s 618ms/step - loss: 0.0494 - accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "STEPS_PER_EPOCH=40\n",
    "\n",
    "model_history = model.fit(data_train, labels_train, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa656b",
   "metadata": {},
   "source": [
    "# Predictions vs. Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "696ccb7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67fb9650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predicted Image')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 10\n",
    "y_pred_processed = (y_pred < 0.6).astype(np.uint8)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(13,13))\n",
    "\n",
    "\n",
    "# Plotting the Ground Truth Image\n",
    "path = labels_test[idx]\n",
    "path = path == 0\n",
    "\n",
    "axs[0].imshow((data_test[idx]).astype(np.uint8),)\n",
    "axs[0].imshow((path*255).astype(np.uint8), cmap='Reds', alpha=0.4)\n",
    "axs[0].set_title(\"Ground Truth Image\")\n",
    "\n",
    "\n",
    "# Plotting the Predicted Image\n",
    "axs[1].imshow((data_test[idx]).astype(np.uint8),)\n",
    "axs[1].imshow((y_pred_processed[idx]*255).astype(np.uint8),  cmap='Reds', alpha=0.4)\n",
    "axs[1].set_title(\"Predicted Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9de17a",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
